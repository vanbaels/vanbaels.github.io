[
  {
    "objectID": "Personal_projects/personal_projects.html",
    "href": "Personal_projects/personal_projects.html",
    "title": "Personal projects",
    "section": "",
    "text": "A closer look at Lego set prices\n\n\n\n\n\n\n\n\n\n\n\nJul 21, 2024\n\n\nSven Van Bael\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html",
    "href": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html",
    "title": "A closer look at Lego set prices",
    "section": "",
    "text": "Many people will be familiar with Lego, the popular construction sets with interlocking brightly coloured plastic bricks. In the later years, Lego marketing has successfully targeted a more adult audience (including myself), with sets that are more intricate and detailed. Every Lego fan, or who knows Lego fans (be it a child or an adult) will also know the sometimes hefty price ranges, especially for the “adult” sets, and those under an intellectual property license (think of Star Wars, Marvel, Minecraft, etc.).\nThanks to the R package brickset I was able to collect data on all Lego sets released during 2018 and 2024, with variables such as set theme, intellectual property license, number of pieces, retail price, etc. By exploring this data set I was curious if I could find an answer to some questions:\n\nAre smaller sets more expensive to produce than bigger ones, i.e. is there a difference in price-to-part ratio?\nIs there a big price difference between intellectual property licensed sets and other sets?\nWhich intellectual property has the most expensive Lego sets?\nWhich set has the lowest price-to-part ratio?"
  },
  {
    "objectID": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#introduction",
    "href": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#introduction",
    "title": "A closer look at Lego set prices",
    "section": "",
    "text": "Many people will be familiar with Lego, the popular construction sets with interlocking brightly coloured plastic bricks. In the later years, Lego marketing has successfully targeted a more adult audience (including myself), with sets that are more intricate and detailed. Every Lego fan, or who knows Lego fans (be it a child or an adult) will also know the sometimes hefty price ranges, especially for the “adult” sets, and those under an intellectual property license (think of Star Wars, Marvel, Minecraft, etc.).\nThanks to the R package brickset I was able to collect data on all Lego sets released during 2018 and 2024, with variables such as set theme, intellectual property license, number of pieces, retail price, etc. By exploring this data set I was curious if I could find an answer to some questions:\n\nAre smaller sets more expensive to produce than bigger ones, i.e. is there a difference in price-to-part ratio?\nIs there a big price difference between intellectual property licensed sets and other sets?\nWhich intellectual property has the most expensive Lego sets?\nWhich set has the lowest price-to-part ratio?"
  },
  {
    "objectID": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#packages-used",
    "href": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#packages-used",
    "title": "A closer look at Lego set prices",
    "section": "2 Packages used",
    "text": "2 Packages used\n\nlibrary(brickset)\nlibrary(tidyverse)\nlibrary(DT)\nlibrary(ggbeeswarm)\nlibrary(ggrepel)"
  },
  {
    "objectID": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#obtaining-data-on-all-lego-sets-released-from-2018-to-2024",
    "href": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#obtaining-data-on-all-lego-sets-released-from-2018-to-2024",
    "title": "A closer look at Lego set prices",
    "section": "3 Obtaining data on all Lego sets released from 2018 to 2024",
    "text": "3 Obtaining data on all Lego sets released from 2018 to 2024\nThe getSets function from the brickset package interfaces with the API on the Brickset website (an active account on this website is required) and returns a data frame containing all Lego sets released for a specified year. Initially, I was planning to create a database with all sets released in the last 5 years (2019-2024). However, being alert for potential COVID-19 related effects (production lags, delayed set releases, …), I instead opted for the 2018-2024 period to have a good amount of pre- and post-COVID-19 data. The combined data frame is available as Lego_sets_18to24.csv\n\ndf_sets_18to24 &lt;- read_csv(\"Lego_sets_18to24.csv\")\nglimpse(df_sets_18to24)\n## Rows: 6,085\n## Columns: 36\n## $ setID                 &lt;dbl&gt; 27724, 27828, 27829, 27830, 28316, 27454, 27455,…\n## $ number                &lt;chr&gt; \"10260\", \"10261\", \"10262\", \"10263\", \"10268\", \"10…\n## $ numberVariant         &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n## $ name                  &lt;chr&gt; \"Downtown Diner\", \"Roller Coaster\", \"James Bond …\n## $ year                  &lt;dbl&gt; 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, …\n## $ theme                 &lt;chr&gt; \"Creator Expert\", \"Creator Expert\", \"Creator Exp…\n## $ themeGroup            &lt;chr&gt; \"Model making\", \"Model making\", \"Model making\", …\n## $ subtheme              &lt;chr&gt; \"Modular Buildings Collection\", \"Fairground Coll…\n## $ category              &lt;chr&gt; \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Normal\"…\n## $ released              &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n## $ pieces                &lt;dbl&gt; 2480, 4124, 1290, 1166, 826, 85, 186, 295, 579, …\n## $ minifigs              &lt;dbl&gt; 6, 11, NA, 8, 3, NA, 1, 2, 2, 3, NA, NA, NA, NA,…\n## $ bricksetURL           &lt;chr&gt; \"https://brickset.com/sets/10260-1\", \"https://br…\n## $ rating                &lt;dbl&gt; 4.3, 4.3, 4.2, 3.9, 4.0, 3.7, 3.9, 3.8, 4.0, 4.1…\n## $ reviewCount           &lt;dbl&gt; 7, 5, 10, 1, 3, 3, 2, 0, 2, 2, 1, 1, 2, 1, 1, 0,…\n## $ packagingType         &lt;chr&gt; \"Box\", \"Box\", \"Box\", \"Box\", \"Box\", \"Box\", \"Box\",…\n## $ availability          &lt;chr&gt; \"LEGO exclusive\", \"LEGO exclusive\", \"LEGO exclus…\n## $ agerange_min          &lt;dbl&gt; 16, 16, NA, 12, 12, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4…\n## $ thumbnailURL          &lt;chr&gt; \"https://images.brickset.com/sets/small/10260-1.…\n## $ imageURL              &lt;chr&gt; \"https://images.brickset.com/sets/images/10260-1…\n## $ US_retailPrice        &lt;dbl&gt; 169.99, 379.99, 149.99, 99.99, 199.99, 4.99, 9.9…\n## $ US_dateFirstAvailable &lt;dttm&gt; 2018-01-01, 2018-06-02, 2018-08-01, 2018-10-02,…\n## $ US_dateLastAvailable  &lt;dttm&gt; 2020-11-24, 2021-11-20, 2022-01-27, 2020-11-20,…\n## $ UK_retailPrice        &lt;dbl&gt; 129.99, 299.99, 129.99, 84.99, 159.99, 4.99, 8.9…\n## $ UK_dateFirstAvailable &lt;dttm&gt; 2018-01-01, 2018-06-02, 2018-08-01, 2018-10-02,…\n## $ UK_dateLastAvailable  &lt;dttm&gt; 2020-11-04, 2021-11-07, 2021-08-02, 2021-03-02,…\n## $ CA_retailPrice        &lt;dbl&gt; 219.99, 479.99, 179.99, 129.99, 249.99, 5.99, 12…\n## $ CA_dateFirstAvailable &lt;dttm&gt; 2018-01-01, 2018-06-02, 2018-08-01, 2018-10-02,…\n## $ CA_dateLastAvailable  &lt;dttm&gt; 2020-11-24, 2021-11-20, 2022-01-27, 2020-11-20,…\n## $ DE_retailPrice        &lt;dbl&gt; 149.99, 329.99, 149.99, 87.72, 175.45, 4.99, 9.9…\n## $ DE_dateFirstAvailable &lt;dttm&gt; 2018-02-02, 2018-06-02, 2018-08-01, 2018-10-02,…\n## $ DE_dateLastAvailable  &lt;dttm&gt; 2020-11-05, 2021-11-15, 2021-08-04, 2020-12-11,…\n## $ height                &lt;dbl&gt; 37.5, 48.6, 28.2, 28.0, 47.5, 9.1, 14.1, 19.1, 2…\n## $ width                 &lt;dbl&gt; 58.0, 58.1, 48.0, 47.7, 37.5, 12.2, 15.7, 26.2, …\n## $ depth                 &lt;dbl&gt; 9.80, 18.60, 9.10, 8.70, 10.70, 5.90, 6.10, 4.60…\n## $ weight                &lt;dbl&gt; NA, 5.800, NA, 1.365, 2.156, NA, NA, NA, NA, NA,…"
  },
  {
    "objectID": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#cleaning-the-dataset",
    "href": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#cleaning-the-dataset",
    "title": "A closer look at Lego set prices",
    "section": "4 Cleaning the dataset",
    "text": "4 Cleaning the dataset\nYou can see that the data frame has a total of 36 columns with an abundance of information that is not useful for this particular analysis. So for the next steps, I will only select the columns setID, number, name, year, theme, themeGroup, subtheme, category, released, pieces, and DE_retailPrice (I’m located in Europe, so I opted for the prices in Euro).\n\ndf_sets_18to24 &lt;- read_csv(\"Lego_sets_18to24.csv\") %&gt;%\n  select(setID, number, name, year, theme, themeGroup, subtheme, category, released, pieces, DE_retailPrice)\nhead(df_sets_18to24, n = 20) %&gt;%\n  datatable()\n\n\n\nTable 1: First 20 rows of sets_18to24.\n\n\n\n\n\n\n\n\n\n\n\nTo make things easier later on, any NAs in subtheme are filled in by the value of the column themeGroup:\n\ndf_sets_18to24$subtheme &lt;- ifelse(is.na(df_sets_18to24$subtheme) == T,\n                                  df_sets_18to24$themeGroup,\n                                  df_sets_18to24$subtheme)\n\nWhile exploring the data further, it seems that the information on intellectual property license is spread over both columns themeGroup or subtheme, with no overlap between the two. As I want to be able to make an easy distinction between licensed and not-licensed, the new column License is created that contains this information. Additionally, the following filters are applied on the data frame:\n\npieces cannot be NA, and is cut-off at 10, because very small sets are often specialized expansion sets such as base plates, road plates, rails, etc.\nDE_retailPrice cannot be NA.\nAs I only focus on actual Lego sets, theme and subtheme cannot be “Duplo”, and category cannot be “Book”.\nreleased equals TRUE, so it only contains sets that have been released on the market.\n\nAnd finally, the column Price-to-part ratio is added, which is calculated from DE_retailPrice and pieces.\n\ndf_sets_18to24_filt &lt;- df_sets_18to24 %&gt;%\n  filter(is.na(pieces) == FALSE,\n         pieces &gt; 10,\n         is.na(DE_retailPrice) == FALSE,\n         theme != \"Duplo\",\n         subtheme != \"Duplo\",\n         category != \"Book\",\n         released == TRUE\n         ) %&gt;%\n  mutate(\"License\" = ifelse(themeGroup == \"Licensed\"|subtheme == \"Licensed\",\n                            \"Licensed\",\n                            \"No license\"),\n         \"Price-to-part ratio\" = DE_retailPrice/pieces)\n\nThe column year is converted into type factor, instead of type double. This will turn it from a continuous variable into a categorical variable, and is necessary when using year as a grouping variable, or when creating plots with ggplot2. Also, the License column is turned into type factor, with the ordered levels “No license” and “License”.\n\ndf_sets_18to24_filt$year &lt;- factor(df_sets_18to24_filt$year)\ndf_sets_18to24_filt$License &lt;- factor(df_sets_18to24_filt$License, levels = c(\"No license\", \"Licensed\"))\n\nhead(df_sets_18to24_filt, n = 20) %&gt;%\n  datatable()\n\n\n\nTable 2: First 20 rows of sets_18to24_filt."
  },
  {
    "objectID": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#visually-exploring-the-data",
    "href": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#visually-exploring-the-data",
    "title": "A closer look at Lego set prices",
    "section": "5 Visually exploring the data",
    "text": "5 Visually exploring the data\nAll of the code that is used to generate each figure is available under “Show code”.\n\n5.1 Number of sets released each year\n\n\nShow code\n#Calculate the number of sets released each year.\ndf_release_yr &lt;- df_sets_18to24_filt %&gt;%\n  group_by(year, License) %&gt;%\n  summarise(\"n_sets\" = n()) %&gt;%\n  mutate(\"All\" = sum(n_sets)) %&gt;%\n  pivot_wider(names_from = License, values_from = n_sets) %&gt;%\n  pivot_longer(cols = c(Licensed, `No license`, All), names_to = \"License\", values_to = \"n_sets\")\n\ndf_release_yr$License &lt;- factor(df_release_yr$License, levels = c(\"No license\", \"Licensed\", \"All\"))\n\n#Plot.\nggplot(df_release_yr) +\n  geom_point(aes(x = year, y = n_sets, color = License, fill = License), pch = 21, size = 3) +\n  geom_line(aes(x = year, y = n_sets, color = License, group = License), linewidth = 1) +\n  scale_x_discrete(name = \"Year\") +\n  scale_y_continuous(name = \"Number of sets\") +\n  coord_cartesian(ylim = c(0, 390)) +\n  scale_color_manual(values = c(\"#9a1917\", \"#d88c0f\", \"#000000\")) +\n  scale_fill_manual(values = c(\"#9a19174D\", \"#d88c0f4D\", \"#0000004D\")) +\n  theme_classic() +\n  theme(axis.title = element_text(size = 18),\n        axis.text = element_text(size = 16, color = \"black\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nFigure 1: Number of non-licensed, licensed, and all sets released from 2018 to 2024.\n\n\n\n\n\nIn Figure 1 you can see that the number of sets released each year is quite stable, with almost an equal number of licensed versus non-licensed sets being released. Interesting is the difference in 2020, where there is a drop in licensed sets, and an increase in the non-licensed ones. Not sure what has caused this difference here, but a good guess is that due to COVID-19 a lot of media releases (movies, tv series, …) have been postponed, which in turn could have resulted in the accompanying Lego sets not being released as well?\nAlso noteworthy is that the number of sets for the years 2023 and 2024 is almost equal. However, the data for 2024 is incomplete, as at the time of writing it is only July 2024, meaning that in 7 months Lego has released almost as many sets as in the entire year of 2023.\n\n\n5.2 Evolution of set sizes and retail prices from 2018 to 2024\n\n\nShow code\n#Calculate the mean piece count of all sets for each year.\ndf_pieces_stats &lt;- df_sets_18to24_filt %&gt;%\n  group_by(year, License) %&gt;%\n  summarize(\"mean pieces\" = mean(pieces),\n            \"sd\" = sd(pieces))\n\n#Plot.\nggplot(df_sets_18to24_filt) +\n  facet_grid(~year) +\n  geom_quasirandom(aes(x = License, y = pieces, color = License, fill = License), pch = 21, size = 3) +\n  geom_point(data = df_pieces_stats, aes(x = License, y = `mean pieces`), size = 3) +\n  scale_y_continuous(name = \"Piece count\", trans = \"log10\", breaks = 10^seq(0, 4, 1)) +\n  scale_color_manual(values = c(\"#9a1917\", \"#d88c0f\")) +\n  scale_fill_manual(values = c(\"#9a19174D\", \"#d88c0f4D\")) +\n  coord_cartesian(ylim = c(10^0, 10^4)) +\n  theme_classic() +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_text(size = 18),\n        axis.text.x = element_blank(),\n        axis.text.y = element_text(size = 16, color = \"black\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14),\n        strip.text = element_text(size = 14, face = \"bold\"))\n\n\n\n\n\n\n\n\nFigure 2: Piece count (axis in log scale) of non-licensed and licensed sets from 2018 to 2024.\n\n\n\n\n\nFigure 2 shows that there is no substantial difference in piece count between licensed and non-licensed sets. Interesting is that the mean piece count of Lego sets has been increasing over the years. In 2018, the mean piece count was 404/430 for non-licensed/licensed sets respectively. By 2024, this has increased to 737/627 for non-licensed/licensed. As a consequence, mean set prizes should have also increased in that time period.\n\n\nShow code\n#Calculate the mean retail price of all sets for each year.\ndf_prices_stats &lt;- df_sets_18to24_filt %&gt;%\n  group_by(year, License) %&gt;%\n  summarize(\"mean retail price\" = mean(DE_retailPrice),\n            \"sd\" = sd(DE_retailPrice))\n\n#Plot\nggplot(df_sets_18to24_filt) +\n  facet_grid(~year) +\n  geom_quasirandom(aes(x = License, y = DE_retailPrice, color = License, fill = License), pch = 21, size = 3) +\n  geom_point(data = df_prices_stats, aes(x = License, y = `mean retail price`), size = 3) +\n  scale_y_continuous(name = \"Retail price (EUR)\", trans = \"log10\") +\n  scale_color_manual(values = c(\"#9a1917\", \"#d88c0f\")) +\n  scale_fill_manual(values = c(\"#9a19174D\", \"#d88c0f4D\")) +\n  coord_cartesian(ylim = c(10^0, 10^3)) +\n  theme_classic() +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_text(size = 18),\n        axis.text.x = element_blank(),\n        axis.text.y = element_text(size = 16, color = \"black\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14),\n        strip.text = element_text(size = 14, face = \"bold\"))\n\n\n\n\n\n\n\n\nFigure 3: Retail prices (axis in log scale) of non-licensed and licensed sets from 2018 to 2024.\n\n\n\n\n\nAs expected, in Figure 3 the mean retail price for sets has increased from 38.57 EUR/45.27 EUR (non-licensed/licensed) in 2018 to 64.85 EUR/66.64 EUR (non-licensed/licensed). This corresponds to the increase in set piece count seen in Figure 2.\n\n\n5.3 Evolution of the price-to-part ratio from 2018 to 2024\nThe most simple way to take into account the effect of the set piece count on the retail price is to calculate the price-to-part ratio.\n\n\nShow code\n#Calculate mean price-to-part ratio for each year.\ndf_ptp_stats &lt;- df_sets_18to24_filt %&gt;%\n  group_by(year) %&gt;%\n  mutate(\"mean PtP ratio - all\" = mean(mean(`Price-to-part ratio`))) %&gt;%\n  group_by(year, License) %&gt;%\n  summarize(\"mean PtP ratio\" = mean(`Price-to-part ratio`),\n            \"median PtP ratio\" = median(`Price-to-part ratio`),\n            \"sd\" = sd(`Price-to-part ratio`))\n\n#Plot.\nggplot(df_sets_18to24_filt) +\n  facet_grid(~year) +\n  geom_quasirandom(aes(x = License, y = `Price-to-part ratio`, color = License, fill = License), dodge.width = 0.5, pch = 21, size = 3) +\n  geom_point(data = df_ptp_stats, aes(x = License, y = `mean PtP ratio`), size = 3) +\n  geom_errorbar(data = df_ptp_stats, aes(x = License, ymin = `mean PtP ratio` - sd, ymax = `mean PtP ratio` + sd), width = 0.2) +\n  scale_color_manual(values = c(\"#9a1917\", \"#d88c0f\")) +\n  scale_fill_manual(values = c(\"#9a19174D\", \"#d88c0f4D\")) +\n  theme_classic() +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_text(size = 18),\n        axis.text.x = element_blank(),\n        axis.text.y = element_text(size = 16, color = \"black\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14),\n        strip.text = element_text(size = 14, face = \"bold\"))\n\n\n\n\n\n\n\n\nFigure 4: Price-to-part ratio (in EUR per piece) of non-licensed and licensed sets from 2018 to 2024.\n\n\n\n\n\nIn general, the price-to-part ratio for licensed sets is indeed slightly higher than those of non-licensed sets, with 2018 being the only exception (Figure 4). While most values clump together, there are some outliers with price-to-part ratios going as high as 1 EUR. Let’s take a closer look by filtering for sets with a price-to-part ratio higher than 0.5 EUR.\n\n\nShow code\n#Filter for sets that have a price-to-part ratio higher than 0.5 EUR\ndf_high_ptp_sets &lt;- filter(df_sets_18to24_filt, `Price-to-part ratio` &gt; 0.5)\ndatatable(df_high_ptp_sets, filter = \"top\")\n\n\n\n\nTable 3: Lego sets with a price-to-part ratio over 0.5 EUR per piece.\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(df_high_ptp_sets$License)\n## No license   Licensed \n##         14          7\nsummary(factor(df_high_ptp_sets$subtheme))\n##      Playmats Power-Up Pack         SPIKE        Stuntz        Trains \n##             3             7             2             8             1\n\nInterestingly, Table 3 contains more non-licensed sets than licensed ones (which are thought to be more expensive). When looking at the subthemes, you can see that the table contains three playmat sets, and one train track extension. These are non-standard sets with non-standard pieces, explaining the high price-to-part ratios. The same reasoning can explain the high ratios for sets of the SPIKE educational theme (aimed at learning programming to kids, contains specialized parts such as motors, sensors, etc.) and the Lego City Stuntz theme (containing flywheel-powered stunt bikes). Finally, there is the Super Mario Power-Up Pack theme, an interactive playset that combines Super Mario gameplay with Lego bricks. As these sets are both licensed and contain specialized electronic parts, it is one of the most expensive in this list, with several sets reaching 0.9 EUR per brick.\nWhen doing a deeper analysis, it could be argued that playmats, train track extensions and educational sets with expensive electronic parts should be excluded when analyzing the pricing of more standard Lego sets. For now, I will keep in mind that 21 sets have very aberrant price-to-part ratios, but that this will probably have little impact on the total of 2526 sets in df_sets_18to24_filt.\nNext, let’s focus on how the mean price-to-part ratio (also shown in Figure 4 as black dots) evolves over the years for both licensed and non-licensed sets:\n\n\nShow code\nggplot(df_ptp_stats) +\n  geom_line(aes(x = year, y = `mean PtP ratio`, color = License, group = License), linewidth = 1) +\n  geom_point(aes(x = year, y = `mean PtP ratio`, color = License, fill = License), pch = 21, size = 3) +\n  scale_x_discrete(name = \"Year\") +\n  scale_y_continuous(name = \"Mean price-to-part ratio\") +\n  coord_cartesian(ylim = c(0, 0.15)) +\n  scale_color_manual(values = c(\"#9a1917\", \"#d88c0f\")) +\n  scale_fill_manual(values = c(\"#9a19174D\", \"#d88c0f4D\")) +\n  theme_classic() +\n  theme(axis.title = element_text(size = 18),\n        axis.text = element_text(size = 16, color = \"black\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nFigure 5: Evolution of the mean price-to-part ratio (in EUR per piece) of non-licensed and licensed sets from 2018 to 2024.\n\n\n\n\n\nIn Figure 5 you can see that - except for 2018 - licensed sets have always been more expensive than non-licensed sets, with the difference ranging from 1.1 cents (2021) to 1.6 cents (2023) per piece. Both licensed and non-licensed sets do follow an identical trend over the years, meaning that price increases/decreases have affected all Lego sets, not just licensed or non-licensed. It’s fair to assume that these changes are probably caused by economical factors (production costs, etc.), as this would indeed affect all sets. Price-to-part ratios started to rise in 2020 and peaked at 2021, and after that decreased and stabilized again. I have no idea about the exact cause of this bump, but a possible explanation could be the effect of COVID-19 on the economy.\n\n\n5.4 Retail price versus set sizes\nLet’s now look at the correlation between piece count and retail price for all the sets that have been released from 2018 to 2024.\n\n\nShow code\n#For all linear regressions, the intercept is set to 0, since a piece count of 0 should also result in a retail price of 0.\n#Linear regression for all sets.\nlm_all &lt;- lm(DE_retailPrice ~ pieces - 1, data = df_sets_18to24_filt)\nsummary(lm_all)\n## \n## Call:\n## lm(formula = DE_retailPrice ~ pieces - 1, data = df_sets_18to24_filt)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -735.91   -0.41    5.36   14.05  436.95 \n## \n## Coefficients:\n##         Estimate Std. Error t value Pr(&gt;|t|)    \n## pieces 0.0843011  0.0006785   124.2   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 35.29 on 2525 degrees of freedom\n## Multiple R-squared:  0.8594, Adjusted R-squared:  0.8594 \n## F-statistic: 1.544e+04 on 1 and 2525 DF,  p-value: &lt; 2.2e-16\n\n#Linear regression for non-licensed sets.\nlm_nonlic &lt;- lm(DE_retailPrice ~ pieces - 1, data = filter(df_sets_18to24_filt, License == \"No license\"))\nsummary(lm_nonlic)\n## \n## Call:\n## lm(formula = DE_retailPrice ~ pieces - 1, data = filter(df_sets_18to24_filt, \n##     License == \"No license\"))\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -583.96    2.00    6.50   15.91  427.34 \n## \n## Coefficients:\n##         Estimate Std. Error t value Pr(&gt;|t|)    \n## pieces 0.0713083  0.0008962   79.57   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 34.07 on 1308 degrees of freedom\n## Multiple R-squared:  0.8288, Adjusted R-squared:  0.8286 \n## F-statistic:  6331 on 1 and 1308 DF,  p-value: &lt; 2.2e-16\n\n#Linear regression for non-licensed sets.\nlm_lic &lt;- lm(DE_retailPrice ~ pieces - 1, data = filter(df_sets_18to24_filt, License == \"Licensed\"))\nsummary(lm_lic)\n## \n## Call:\n## lm(formula = DE_retailPrice ~ pieces - 1, data = filter(df_sets_18to24_filt, \n##     License == \"Licensed\"))\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -301.50   -3.24    3.80   12.06  394.00 \n## \n## Coefficients:\n##         Estimate Std. Error t value Pr(&gt;|t|)    \n## pieces 0.0991981  0.0008485   116.9   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 30.12 on 1216 degrees of freedom\n## Multiple R-squared:  0.9183, Adjusted R-squared:  0.9182 \n## F-statistic: 1.367e+04 on 1 and 1216 DF,  p-value: &lt; 2.2e-16\n\n#Getting the slope from the fitted models.\nslope_all &lt;- lm_all$coefficients[1]\nslope_nonlic &lt;- lm_nonlic$coefficients[1]\nslope_lic &lt;- lm_lic$coefficients[1]\n\n#Plot.\nggplot(df_sets_18to24_filt) +\n  geom_point(aes(x = pieces, y = DE_retailPrice, color = License, fill = License), pch = 21, size = 3) +\n  geom_abline(slope = slope_all, color = \"black\", lty = 1) +\n  geom_abline(slope = slope_nonlic, color = \"#9a1917\", lty = 1) +\n  geom_abline(slope = slope_lic, color = \"#d88c0f\", lty = 1) +\n  geom_text(aes(x = 8700, y = 925, label = paste0(\"slope = \", round(slope_lic, 4))), color = \"#d88c0f\", angle = 36.3, size = 5) +\n    geom_text(aes(x = 9400, y = 840, label = paste0(\"slope = \", round(slope_all, 4))), color = \"black\", angle = 32.1, size = 5) +\n      geom_text(aes(x = 11000, y = 830, label = paste0(\"slope = \", round(slope_nonlic, 4))), color = \"#9a1917\", angle = 28.2, size = 5) +\n  scale_x_continuous(name = \"Piece count\", breaks = seq(0, 12000, 2000)) +\n  scale_y_continuous(name = \"Retail price (EUR)\", breaks = seq(0, 1000, 200)) +\n  scale_color_manual(values = c(\"#9a1917\", \"#d88c0f\")) +\n  scale_fill_manual(values = c(\"#9a19174D\", \"#d88c0f4D\")) +\n  coord_cartesian(xlim = c(0, 12000), ylim = c(0, 1000)) +\n  theme_classic() +\n  theme(axis.title = element_text(size = 18),\n        axis.text = element_text(size = 16, color = \"black\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nFigure 6: Correlation between set piece count and retail price for all sets released in 2018 to 2024. Linear regression models are made for non-licensed, licensed, and all sets.\n\n\n\n\n\nFrom Figure 5, we know already that there is indeed a price difference between licensed and non-licensed sets, so it is not a complete surprise that the fitted linear regressions differs when sub setting for licensed and non-licensed sets ( Figure 6 ). In a way, the slope of these linear regressions can be seen as an alternative way to estimate the price-to-part ratio, since multiplying the slope by the piece count results in the retail price (or more correctly: an estimation of the retail price according to the fitted linear model).\nYou can find the full details of the three fitted linear models in the code used to generate Figure 6. All three have an R2 between 0.83 and 0.92 , which shows that they are a pretty good fit for the data. From this you could conclude that the correlation between piece count and retail price is pretty linear, meaning that sets with a high piece count do not become cheaper to produce.\nTo have a look at what are the cheapest and most expensive sets within each category (licensed/non-licensed), I want to select the sets that deviate strongly from the linear regression. To have an idea for the cut-off to use for outliers, I used the standard deviation on the retail price of all sets (which is 74.5 EUR) and increased this to 100 EUR. I then used this to filter df_sets_18to24_filt for licensed sets where the retail price deviates more than 100 EUR upwards of the fitted linear regression.\n\n\nShow code\n#Filter for licensed sets that deviate 100 EUR above the fitted linear regression \ndf_lic_exp &lt;- df_sets_18to24_filt %&gt;%\n  filter(DE_retailPrice &gt; (slope_lic*pieces) + 100) %&gt;%\n  filter(License == \"Licensed\") %&gt;%\n  mutate(\"Dev_lm\" = abs((slope_lic*pieces + 100) - DE_retailPrice))\n\n#Plot.\nggplot(df_lic_exp) +\n  geom_point(aes(x = pieces, y = DE_retailPrice, color = License, fill = License), pch = 21, size = 3) +\n  geom_abline(slope = slope_lic, color = \"#d88c0f\", lty = 1) +\n  geom_abline(slope = slope_lic, intercept = 100, color = \"#d88c0f\", lty = 2) +\n    geom_text_repel(aes(x = pieces, y = DE_retailPrice, label = name), box.padding = 0.25, max.overlaps = Inf, segment.curvature = -0.1, segment.ncp = 3, segment.angle = 20, min.segment.length = 0.25) +\n  scale_x_continuous(name = \"Piece count\", breaks = seq(0, 12000, 2000)) +\n  scale_y_continuous(name = \"Retail price (EUR)\", breaks = seq(0, 1000, 200)) +\n  scale_color_manual(values = c(\"#d88c0f\")) +\n  scale_fill_manual(values = c(\"#d88c0f4D\")) +\n  coord_cartesian(xlim = c(0, 12000), ylim = c(0, 1000)) +\n  theme_classic() +\n  theme(axis.title = element_text(size = 18),\n        axis.text = element_text(size = 16, color = \"black\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nFigure 7: Licensed sets that deviate more than 100 EUR above the linear regression of licensed sets (indicated by the dashed line).\n\n\n\n\n\nNot a lot of surprises in Figure 7, showing sets that already were known for their hefty retail price. Absolute champion is the Liebherr Crawler Crane (42146), where not only the license, but also the included motors and control app have its effect on the retail price. In second place is the Star Wars Imperial Star Destroyer (75252).\nSimilarly, I looked at the licensed sets that are on the cheap end of the fitted linear regression:\n\n\nShow code\n#Filter for licensed sets that deviate 100 EUR below the fitted linear regression.\ndf_lic_chp &lt;- df_sets_18to24_filt %&gt;%\n  filter(DE_retailPrice &lt; (slope_lic*pieces) - 100) %&gt;%\n  filter(License == \"Licensed\") %&gt;%\n  mutate(\"Dev_lm\" = abs((slope_lic*pieces - 100) - DE_retailPrice))\n\n#Plot.\nggplot(df_lic_chp) +\n  geom_point(aes(x = pieces, y = DE_retailPrice, color = License, fill = License), pch = 21, size = 3) +\n  geom_abline(slope = slope_lic, color = \"#d88c0f\", lty = 1) +\n  geom_abline(slope = slope_lic, intercept = -100, color = \"#d88c0f\", lty = 2) +\n  geom_text_repel(aes(x = pieces, y = DE_retailPrice, label = name), box.padding = 0.25, max.overlaps = Inf, segment.curvature = -0.1, segment.ncp = 3, segment.angle = 20, min.segment.length = 0.25) +\n  scale_y_continuous(name = \"Retail price (EUR)\", breaks = seq(0, 1000, 200)) +\n  scale_x_continuous(name = \"Piece count\", breaks = seq(0, 12000, 2000)) +\n  scale_color_manual(values = c(\"#d88c0f\")) +\n  scale_fill_manual(values = c(\"#d88c0f4D\")) +\n  coord_cartesian(xlim = c(0, 12000), ylim = c(0, 1000)) +\n  theme_classic() +\n  theme(axis.title = element_text(size = 18),\n        axis.text = element_text(size = 16, color = \"black\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nFigure 8: Licensed sets that deviate more than 100 EUR below the linear regression of licensed sets (indicated by the dashed line).\n\n\n\n\n\nFigure 8 shows two contenders for the cheapest licensed set: Harry Potter Hogwarts Crests (31201), and Jim Lee Batman Collection (31205). Both sets are part of the Lego Art theme, and use 1x1 round plates and/or tiles to create what is in essence a pixel artwork. Content-wise, the vast majority of these sets consist of these tiny 1x1 round plates/tiles, which do not require a lot of plastic to produce, making them cheap. Indeed, even the next three cheapest sets in line are again in the Lego Art theme: Star Wars The Sith (31200), Marvel Studios Iron Man (31199), and Disney’s Mickey Mouse (31202). The first non-Art set is Hogwart’s Castle, a microfig scale rendition of the eponymous castle from Harry Potter.\nFollowing the same principle, I filtered for the most expensive non-licensed sets:\n\n\nShow code\n#Filter for non-licensed sets that deviate 100 EUR above the fitted linear regression.\ndf_nonlic_exp &lt;- df_sets_18to24_filt %&gt;%\n  filter(DE_retailPrice &gt; (slope_nonlic*pieces) + 100) %&gt;%\n  filter(License == \"No license\") %&gt;%\n  mutate(\"Dev_lm\" = abs((slope_nonlic*pieces + 100) - DE_retailPrice))\n\n#Plot.\nggplot(df_nonlic_exp) +\n  geom_point(aes(x = pieces, y = DE_retailPrice, color = License, fill = License), pch = 21, size = 3) +\n  geom_abline(slope = slope_nonlic, color = \"#9a1917\", lty = 1) +\n  geom_abline(slope = slope_nonlic, intercept = +100, color = \"#9a1917\", lty = 2) +\n    geom_text_repel(aes(x = pieces, y = DE_retailPrice, label = name), box.padding = 0.25, max.overlaps = Inf, segment.curvature = -0.1, segment.ncp = 3, segment.angle = 20, min.segment.length = 0.25, max.iter = 30000, force = 5) +\n  scale_x_continuous(name = \"Piece count\", breaks = seq(0, 12000, 2000)) +\n  scale_y_continuous(name = \"Retail price (EUR)\", breaks = seq(0, 1000, 200)) +\n  scale_color_manual(values = c(\"#9a1917\")) +\n  scale_fill_manual(values = c(\"#9a19174D\")) +\n  coord_cartesian(xlim = c(0, 12000), ylim = c(0, 1000)) +\n  theme_classic() +\n  theme(axis.title = element_text(size = 18),\n        axis.text = element_text(size = 16, color = \"black\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nFigure 9: Non-licensed sets that deviate more than 100 EUR above the linear regression of non-licensed sets.\n\n\n\n\n\nThe first three most expensive sets in Figure 9 are part of the educational SPIKE theme (45678 and 45345) or Mindstorms (51515), which explains their high price. Fourth place is the 4x4 X-Treme Off-Roader Technic set, coming with motors and a control app, again explaining its higher price. Fifth is the first real model set: the Motorized Lighthouse (21335), which - as the name implies - also comes with a motor, but is first and foremost a Lego model set.\n\n\nShow code\n#Filter for non-licensed sets that deviate 100 EUR below the fitted linear regression.\ndf_nonlic_chp &lt;- df_sets_18to24_filt %&gt;%\n  filter(DE_retailPrice &lt; (slope_nonlic*pieces) - 100) %&gt;%\n  filter(License == \"No license\") %&gt;%\n  mutate(\"Dev_lm\" = abs((slope_nonlic*pieces - 100) - DE_retailPrice))\n\n#Plot.\nggplot(df_nonlic_chp) +\n  geom_point(aes(x = pieces, y = DE_retailPrice, color = License, fill = License), pch = 21, size = 3) +\n  geom_abline(slope = slope_nonlic, color = \"#9a1917\", lty = 1) +\n  geom_abline(slope = slope_nonlic, intercept = -100, color = \"#9a1917\", lty = 2) +\n  geom_text_repel(aes(x = pieces, y = DE_retailPrice, label = name), box.padding = 0.25, max.overlaps = Inf, segment.curvature = -0.1, segment.ncp = 3, segment.angle = 20, min.segment.length = 0.25, max.iter = 30000, force = 5) +\n  scale_x_continuous(name = \"Piece count\", breaks = seq(0, 12000, 2000)) +\n  scale_y_continuous(name = \"Retail price (EUR)\", breaks = seq(0, 1000, 200)) +\n  scale_color_manual(values = c(\"#9a1917\")) +\n  scale_fill_manual(values = c(\"#9a19174D\")) +\n  coord_cartesian(xlim = c(0, 12000), ylim = c(0, 1000)) +\n  theme_classic() +\n  theme(axis.title = element_text(size = 18),\n        axis.text = element_text(size = 16, color = \"black\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank(),\n        legend.text = element_text(size = 14))\n\n\n\n\n\n\n\n\nFigure 10: Non-licensed sets that deviate more than 100 EUR below the linear regression of non-licensed sets.\n\n\n\n\n\nFigure 10 is an easy one: every single set on here is an Art theme mosaic set consisting mostly of 1x1 plates and tiles. As was mentioned in Figure 8, these parts are cheap to produce, and make up most of the sets, explaining their cheaper price range."
  },
  {
    "objectID": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#summary",
    "href": "Personal_projects/posts/LegoSetPrices/LegoSetPrices.html#summary",
    "title": "A closer look at Lego set prices",
    "section": "6 Summary",
    "text": "6 Summary\nFrom this quick exploration of the Lego dataset, we can extract the following conclusions:\n\nLego overall retail prices have increased between 2018 and 2024, but so have the set sizes. Lego seems to release progresively bigger sets (Figure 2), possibly because they increasingly target an older audience that prefers more detailed and intricate models. As a logical consequence, the overall retail prices increase as well (Figure 3).\nPrice-to-part ratios are consistently higher for licensed sets. As expected, licensed sets have an increased price-to-part ratio, with a difference ranging from 1.1 - 1.6 cents per piece (Figure 5). Both licensed and non-licensed sets follow the same trends from 20218 to 2024, indicating that external (economic) factors influence the price of all sets equally.\nSet piece count and retail price follow a linear correlation. Set retail price is independent of the set size (except for some sets with highly specialized parts, see Table 3). Hence, bigger sets are not cheaper to produce than smaller ones.\nThe Lego Art theme has the cheapest price-to-part ratio. It does not matter if they’re licensed (Figure 8) or not (Figure 10), several of the Art theme sets end up being the cheapest in both categories. Possible explanation is that the sets are mainly 1x1 round plates and tiles.\nLiebherr Crawler Crane LR 13000 (42146) and 4x4 X-Treme Off-Roader (42099) are the most expensive sets in the licensed and non-licensed category. In the non-licensed category, the 4x4 X-Treme Off-Roader is preceded by three SPIKE and Mindstorm sets (Figure 9), but these can be considered highly specialized and don’t really fall into the Lego model set category.\nSecond places go to the Star Wars Imperial Star Destroyer (75252), and the Motorized Lighthouse (21335).\n\nAll-in-all it is interesting to see that the price-to-part ratio did increase a during what was probably a COVID-induced (?) economical situation (Figure 5). As of 2024, it looks like this has stabilized to the pre-2020 situation. With Lego releasing increasingly bigger sets (Figure 2), this might give the impression that Lego sets overall are getting more and more expensive, but as we see from the price-to-part ratio, the opposite is actually true (at least for the years 2018-2024)."
  },
  {
    "objectID": "Academic_work/academic_work.html",
    "href": "Academic_work/academic_work.html",
    "title": "Academic work",
    "section": "",
    "text": "Calculating the net charge of a peptide\n\n\n\n\n\n\n\n\n\n\n\nJul 27, 2024\n\n\nSven Van Bael\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Academic_work/posts/PepNetCharge/PepNetCharge.html",
    "href": "Academic_work/posts/PepNetCharge/PepNetCharge.html",
    "title": "Calculating the net charge of a peptide",
    "section": "",
    "text": "This post describes a workflow for calculating the charge of a peptide from its amino acid composition. I start first with a quite extensive introduction on the origin of the formulas that are used. If you want to see the R code directly, go to Section 3."
  },
  {
    "objectID": "Academic_work/posts/PepNetCharge/PepNetCharge.html#packages-used",
    "href": "Academic_work/posts/PepNetCharge/PepNetCharge.html#packages-used",
    "title": "Calculating the net charge of a peptide",
    "section": "1 Packages used",
    "text": "1 Packages used\n\nlibrary(tidyverse) \nlibrary(DT)"
  },
  {
    "objectID": "Academic_work/posts/PepNetCharge/PepNetCharge.html#introduction",
    "href": "Academic_work/posts/PepNetCharge/PepNetCharge.html#introduction",
    "title": "Calculating the net charge of a peptide",
    "section": "2 Introduction",
    "text": "2 Introduction\nA lot of my academic work involved peptides, which are in essence short proteins that are typically around 5 to 20 amino acids long. A major part of my (post)doctoral project was using mass spectrometry to identify and quantify peptides in biological samples. A fundamental principle of mass spectrometry is that it measures the mass-to-charge ratios (m/z) of everything it was able to measure in a sample. Consequently, for quantification purposes I need to input the mass-to-charge ratios of my peptides of interest into the machine. While calculating the monoisotopic mass of a peptide is straightforward (summing the individual amino acid masses that make up the peptide), calculating the charge at a certain pH is slightly less trivial.\nThe method described below is based on two publications by Moore (1985) and Cameselle et al. (1986).\n\n2.1 Identifying all ionizable groups within a peptide\nContributing to the overall charge of a peptide are: the N-terminus (amino group), the C-terminus (carboxyl group), and the amino acids that have ionisable side chains: lysine (amino group), arginine (guanidino group), histidine (imidazole), glutamic acid (carboxyl group), aspartic acid (carboxyl group), cysteine (sulfhydryl) and tyrosine (phenol group). For amino acids, these can be divided into two types:\n\nGroups that have no charge at low pH and become negatively charged at high pH: carboxyl (COOH/COO-), sulfhydryl (SH/S-), and phenol (PhOH/PhO-).\nGroups that are positively charged at low pH and become neutral at high pH: amino (NH3+/NH3), guanidino (guanidino+/guanidino), and imidazole (imidazole+/imidazole).\n\nIf the charge of each of the aforementioned groups is known, the charge \\(Z\\) of a peptide at a given pH can simply be calculated by summing all the individual charges:\n\\[\n\\begin{align*}\nZ_{peptide} = Z_{N-term} &+ Z_{C-term}\n\\\\\n& + n\\cdot Z_{Lys}\n\\\\\n& + n\\cdot Z_{Arg}\n\\\\\n& + n\\cdot Z_{His}\n\\\\\n& + n\\cdot Z_{Glu}\n\\\\\n& + n\\cdot Z_{Asp}\n\\\\\n& + n\\cdot Z_{Cys}\n\\\\\n& + n\\cdot Z_{Tyr}\n\\end{align*}\n\\tag{1}\\]\nWhere \\(n\\) is the number of each corresponding amino acid present in the peptide. The question now is: how to calculate the charge \\(Z\\) for each element in question?\n\n\n2.2 Calculating the fraction of charged/neutral molecules\nThe Henderson-Hasselbalch equation states that the pH of a solution can be calculated from the acid dissociation constant (\\(pK_a\\))and the concentration of dissociated (\\(A^-\\)) and undissociated (\\(HA\\)) molecules.\n\\[\npH = pK_a + log \\frac{[A^-]}{[HA]}\n\\tag{2}\\]\nWhich can be rewritten as:\n\\[\n10^{pH-pK_a}=\\frac{[A^-]}{[HA]}\n\\tag{3}\\]\nIf you express the total number of molecules in solution as 100%, this means that \\([A^-]+[HA]=1\\) or, when rewritten: \\([HA]=1-[A^-]\\). Plugging this into Equation 3 results in:\n\\[\n10^{pH-pK_a} = \\frac{[A^-]}{1-[A^-]}\n\\tag{4}\\]\nRearranging for \\([A^-]\\) gives:\n\\[\n[A^-] = \\frac{1}{10^{pK_a-pH} + 1}\n\\tag{5}\\]\nAnd since it was earlier established that \\([HA] = 1 - [A^-]\\):\n\\[\n\\begin{align*}\n[HA] &= 1 - \\frac{1}{10^{pK_a-pH}+1}\n\\\\\n[HA] &= \\frac{1}{10^{pH-pK_a}+1}\n\\end{align*}\n\\tag{6}\\]\n\n\n2.3 Using the \\([A^-]\\) and \\([HA]\\) fractions to calculate overall charge\nIn Section 2.1, the distinction was made between the ionizable groups within a peptide that have a negative charge (-1) when dissociated versus those that have a positive charge (+1) when undissociated. Using the formulas derived from the Henderson-Hasselbalch equation, each fraction can now be calculated.\nLet’s take the C-terminus as an example: the \\(pK_a\\) of an amino acid carboxyl group is ~3.5, and has a negative charge when dissociated, so the formula for \\([A^-]\\) is used to calculate the fraction of dissociated molecules. With a pH of 7 as example, this gives:\n\\[\n\\begin{align*}\n[A^-] &= \\frac{1}{10^{pK_a-pH}+1}\n\\\\\n&= \\frac{1}{10^{3.5-7}+1}\n\\\\\n&= 99.9\\%\n\\end{align*}\n\\tag{7}\\]\nSo 99.9% of the time, the carboxyl group is in the dissociated form (COO-) at pH = 7. Since the charge of a dissociated carboxyl group equals -1, the mean charge \\(Z_{C-term}\\) is \\(0.999 \\times -1 = -0.999\\) at pH = 7. Note that the 0.01% that is in the undissociated COOH form is not ionized, and therefore does not contribute to the overall charge.\nThe same principle can be applied to the N-terminus, but as this group only carries a charge when undissociated, the formula for \\([HA]\\) is used:\n\\[\n\\begin{align*}\n[HA] &= \\frac{1}{10^{pH-pK_a}+1}\n\\\\\n&= \\frac{1}{10^{7-7.5} + 1}\n\\\\\n&= 76\\%\n\\end{align*}\n\\tag{8}\\]\nWith 76% of the molecules in the positively charged nondissociated form (NH3+), the mean charge \\(Z_{N-term}\\) equals \\(0.76 \\times (+1) = 0.76\\) at pH = 7. Again, the 24% that are in the dissociated NH2 form do not carry a charge, and therefore do not contribute.\nCalculating the charges carried by the amino acid side chains is analogous. For this example, the peptide has no amino acids with ionizable side chains, so Equation 1 can be simplified to calculate the overall charge of the peptide at pH = 7:\n\\[\n\\begin{align*}\nZ_{peptide} &= Z_{N-term} + Z_{C-term}\n\\\\\n&= 0.76 + (-0.999)\n\\\\\n&= -0.239\n\\end{align*}\n\\tag{9}\\]\nSince the outcomes of Equation 7 and 8 still needed to be multiplied by the value 1 or -1 for positively or negatively charged ions, Equation 5 and 6 can be generalized as:\n\\[\n\\begin{align*}\nZ^- &= \\frac{-1}{10^{pK_a-pH}+1}\n\\\\\nZ^+ &= \\frac{+1}{10^{pH-pK_a}+1}\n\\end{align*}\n\\tag{10}\\]\n\n\n2.4 The pKa values of the termini and amino acid side chains\nThere are different sources available for the pKa values of N- and C-termini of amino acids and their side chains. From experience, the resource provided by Bjellqvist et al. (1993) has given the best results, with predicted charge states that correspond well with my own empirically obtained data.\n\ndf_bjellqvist &lt;- read_csv(\"pK values - Bjellqvist.csv\")\ndf_bjellqvist &lt;- column_to_rownames(df_bjellqvist, var = \"Single-letter code\")\ndatatable(df_bjellqvist)\n\n\n\nTable 1: Bjellqvist pKa values for termini and side chains of all 20 amino acids."
  },
  {
    "objectID": "Academic_work/posts/PepNetCharge/PepNetCharge.html#sec-writing-the-r-function",
    "href": "Academic_work/posts/PepNetCharge/PepNetCharge.html#sec-writing-the-r-function",
    "title": "Calculating the net charge of a peptide",
    "section": "3 Creating the R function",
    "text": "3 Creating the R function\nUsing the formulas in 10 and the pKa information from Bjellqvist, I created the function computeCharge that calculates the net charge of a peptide at a given pH.\n\ncomputeCharge &lt;- function(Peptide, pH){\n  #Get amino acid composition from peptide\n  pept &lt;- unlist(str_split(Peptide, \"\"))\n  if (sum(!pept %in% rownames(df_bjellqvist)) &gt; 0){\n    #Abort function when the Peptide string contains letters that do not correspond with an amino acid.\n    warning(\"Peptide string contains unknown amino acid character(s). Please check.\")\n  } else {\n    compoAA &lt;- pept %&gt;%\n    factor(., levels = LETTERS) %&gt;%\n    table()\n  \n    #Get the N-terminal and C-terminal amino acid\n    nTermAA &lt;- pept[1]\n    cTermAA &lt;- pept[length(pept)]\n  \n    #Calculate charge for N- and C-termini and amino acid residues with the pKa information from df_bjellqvist\n    cter &lt;- -1/(10^(df_bjellqvist[cTermAA, \"pK1\"] - pH) + 1)\n    nter &lt;- 1/(10^(pH - df_bjellqvist[nTermAA, \"pK2\"]) + 1)\n  \n    carg &lt;- as.vector(compoAA['R'] * (1/(10^(pH - df_bjellqvist[\"R\", \"pKr\"]) + 1)))\n    chis &lt;- as.vector(compoAA['H'] * (1/(10^(pH - df_bjellqvist[\"H\", \"pKr\"]) + 1)))\n    clys &lt;- as.vector(compoAA['K'] * (1/(10^(pH - df_bjellqvist[\"K\", \"pKr\"]) + 1)))\n  \n    casp &lt;- as.vector(compoAA['D'] * (-1/(10^(df_bjellqvist['D', \"pKr\"] - pH) + 1)))\n    cglu &lt;- as.vector(compoAA['E'] * (-1/(10^(df_bjellqvist['E', \"pKr\"] - pH) + 1)))\n    ccys &lt;- as.vector(compoAA['C'] * (-1/(10^(df_bjellqvist['C', \"pKr\"] - pH) + 1)))\n    ctyr &lt;- as.vector(compoAA['Y'] * (-1/(10^(df_bjellqvist['Y', \"pKr\"] - pH) + 1)))\n  \n    charge &lt;- cter + casp + cglu + ccys + ctyr + nter + carg + chis + clys\n    return(charge)\n  }\n}\n\nLet’s test the function using the peptide sequence DGLDAASYYAPVR, which is part of a standard for retention time calibration (Escher et al., 2012). Typically, samples for mass spectrometric analyses are dissolved in a highly acidic buffer containing 0.1% formic acid, which has a pH of ~2.7, so this value will be used as input.\n\ncomputeCharge(\"DGLDAASYYAPVR\", 2.7)\n## [1] 1.790697\n\nThe value of 1.79 can be interpreted that there both are molecules with charge +1 and charge +2 present, but since the calculated charge is closer to +2, the vast majority will be doubly charged. If necessary, the fraction \\(f\\) of doubly charged molecules can be calculated as follows:\n\\[\n\\begin{align*}\nf \\times (+2) + (1-f) \\times (+1) &= 1.79\n\\\\\n2f - f + 1 &= 1.79\n\\\\\nf &= 0.79\n\\end{align*}\n\\]\nHence, 79% of the molecules are doubly charged while 21% (1 - 0.79 = 0.21) are singly charged.\nIn a second example, let’s test the peptide ECCHGDLLECADDR, which originates from the bovine serum albumin protein (BSA).\n\ncomputeCharge(\"ECCHGDLLECADDR\", 2.7)\n## [1] 2.712474\n\nAgain, the majority of this peptide will be triply charged. The exact ratios can be calculated as before, but now for +2 and +3 charges:\n\\[\n\\begin{align*}\nf \\times (+3) + (1 - f) \\times (+2) &= 2.71\n\\\\\n3f+2-2f &= 2.71\n\\\\\nf &= 0.71\n\\end{align*}\n\\]\nSo 71% of this peptide occurs as triply charged, with 29% being doubly charged."
  },
  {
    "objectID": "Academic_work/posts/PepNetCharge/PepNetCharge.html#creating-a-charge-profile-along-the-ph-scale",
    "href": "Academic_work/posts/PepNetCharge/PepNetCharge.html#creating-a-charge-profile-along-the-ph-scale",
    "title": "Calculating the net charge of a peptide",
    "section": "4 Creating a charge profile along the pH scale",
    "text": "4 Creating a charge profile along the pH scale\nIn some situations, it can be interesting to see how the charge of a peptide changes over the pH range. For this purpose, I used my computeCharge function to plot a charge profile. As an example peptide, I used EAVSEILETSR, a peptide tag described by Vandemoortele et al. (2016).\n\n#Define example peptide\npept_1 &lt;- \"EAVSEILETSR\"\n\n#Iterate the computeCharge function over the entire pH scale\ndf_pH &lt;- tibble(\"pH\" = seq(0, 14, 0.2),\n                \"Charge\" = sapply(pH, computeCharge, Peptide = pept_1))\n\n#Set maximum of the charge axis\ny_scale &lt;- max(abs(df_pH$Charge)) %&gt;% ceiling()\n\n#Plot\nggplot(df_pH) +\n  geom_hline(yintercept = 0, color = \"#565253\", lty = 2) +\n  geom_vline(xintercept = 7, color = \"#565253\", lty = 2) +\n  geom_line(aes(x = pH, y = Charge), color = \"#033e57\") +\n  scale_x_continuous(limits = c(0, 14), breaks = seq(0, 14, 1)) +\n  scale_y_continuous(limits = c(-y_scale, y_scale), breaks = seq(-y_scale, y_scale, 1)) +\n  labs(title = pept_1) +\n  theme_classic() +\n  theme(axis.text = element_text(size = 16, color = \"black\"),\n        axis.title = element_text(size = 18, face = \"bold\"),\n        plot.title = element_text(hjust = 0.5, size = 18, face = \"bold\"))\n\n\n\n\n\n\n\nFigure 1: Charge profile of EAVSEILETSR along the pH scale"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sven Van Bael",
    "section": "",
    "text": "Mail\n  \n  \n    \n     CV\n  \n  \n    \n     Scholar\n  \n  \n    \n     ORCID\n  \n\n  \n  \nHi!\nI’m a former (post)doctoral researcher at KU Leuven/University of Antwerp with a strong interest in data science and data visualization. During my academic career, I have gained a lot of experience with critically analysing large datasets and applying statistical methods to turn raw data into meaningful conclusions.\nOn this website I have collected some of my work with R and RStudio. This ranges from personal projects based on my own interests and curiosity, to some of my academic work, where I used R to answer some of my research questions.\nWant to know more about me? Check the left pane of this page. You can contact me via mail, or explore my CV and list of academic publications."
  }
]